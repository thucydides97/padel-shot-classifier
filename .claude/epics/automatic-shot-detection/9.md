---
name: Validate accuracy on test videos
status: open
created: 2025-11-22T21:39:47Z
updated: 2025-11-22T21:39:47Z
github: [Will be updated when synced to GitHub]
depends_on: [006]
parallel: true
conflicts_with: []
---

# Task: Validate accuracy on test videos

## Description
Test the shot detector on multiple videos with manual annotations to validate accuracy meets the 85% precision/recall targets and boundary accuracy within Â±10 frames.

## Acceptance Criteria
- [ ] Test on minimum 5 videos with diverse shots
- [ ] Calculate precision (true positives / detected shots)
- [ ] Calculate recall (true positives / actual shots)
- [ ] Measure boundary accuracy (frames off from ground truth)
- [ ] Document results and any threshold tuning
- [ ] Precision >= 85%, Recall >= 85%

## Technical Details
**Validation process:**
1. Run detector on test video
2. Compare detected shots to manual annotations
3. Match shots with IoU (intersection over union) threshold
4. Calculate metrics

**Metrics calculation:**
```python
def calculate_metrics(detected, ground_truth, iou_threshold=0.5):
    matches = match_shots(detected, ground_truth, iou_threshold)

    true_positives = len(matches)
    false_positives = len(detected) - true_positives
    false_negatives = len(ground_truth) - true_positives

    precision = true_positives / (true_positives + false_positives)
    recall = true_positives / (true_positives + false_negatives)

    boundary_errors = [abs(d.start - g.start) + abs(d.end - g.end)
                      for d, g in matches]

    return precision, recall, np.mean(boundary_errors)
```

**Test videos needed:**
- At least 5 videos with manual annotations
- Mix of all shot types
- Varying video qualities and angles

**Files affected:**
- tests/test_shot_detector.py (new)
- Validation results documentation

## Dependencies
- [ ] Task 006 - CLI interface (to run detector)
- [ ] Test videos with manual annotations

## Effort Estimate
- Size: M
- Hours: 4-6
- Parallel: true (can run while integration is done)

## Definition of Done
- [ ] Validation script created
- [ ] Tested on 5+ annotated videos
- [ ] Precision >= 85% achieved
- [ ] Recall >= 85% achieved
- [ ] Results documented
- [ ] Threshold tuning documented if needed
